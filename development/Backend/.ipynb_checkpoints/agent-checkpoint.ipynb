{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f18c30-b99f-49be-989a-3dba194e2e0e",
   "metadata": {},
   "source": [
    "# Data Group(DG) Consulting's Agent\n",
    "\n",
    "The following code contains multi-stage steps to build a Data Analyst/Reporter AI Agent using langGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee5782-2591-4d01-a5e8-57d4c26e7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()  \n",
    "google_api = os.getenv(\"GOOGLE-AI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", api_key=google_api, temperature=0)\n",
    "messages = [HumanMessage(content=\"Tell me a fun fact about something from number theory\")]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "print(\"âœ… All good!\") #Poor man's tool, but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027dd19-0eca-4e4c-8720-b1bcc345605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "\n",
    "# Import your agent here (convert notebook code into a .py file if needed)\n",
    "# from my_agent import MyAgent\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"], allow_methods=[\"*\"], allow_headers=[\"*\"]\n",
    ")\n",
    "\n",
    "@app.post(\"/run-agent\")\n",
    "async def run_agent(file: UploadFile):\n",
    "    content = await file.read()\n",
    "    text = content.decode(\"utf-8\")\n",
    "\n",
    "    # Replace with your actual agent call:\n",
    "    # result = MyAgent.invoke({\"fileContent\": text})\n",
    "    result = f\"Got {len(text)} characters\"\n",
    "\n",
    "    return {\"result\": result}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088cd0e-eb45-46fc-9820-4ddffafaf52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_text = text  # text read from uploaded file\n",
    "df = pd.read_csv(StringIO(csv_text))\n",
    "\n",
    "# Now your agent/tool can analyze the DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6183f9-b925-499f-9636-6d5ebabe18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import Tool\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "# Run code directly\n",
    "output = python_repl.run(\"print(1+1)\")\n",
    "print(output)\n",
    "\n",
    "# Create a tool for agents\n",
    "tools = [\n",
    "    Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"Use this Python sandbox to run Python code for data analysis tasks. \"\n",
    "        \"It has pandas installed, so you can read and process tabular data, \"\n",
    "        \"generate summary statistics, and create reports. \"\n",
    "        \"Always print the results so they are returned.\",\n",
    "    func=python_repl.run,)\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# In FastAPI:\n",
    "\n",
    "# result = agent.run(text)\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa2cd2-4166-4f11-a202-3618117416e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with generating python code that will create a data analysis report using the pandas library in the python environment.\")\n",
    "\n",
    "# print(llm_with_tools.invoke([sys_msg]))\n",
    "\n",
    "# *******************************************************************************************************************************************************************************************\n",
    "\n",
    "# from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# sys_msg = SystemMessage(\n",
    "#     content=\"You are a helpful assistant tasked with generating python code that will create a data analysis report using the pandas library in the python environment.\"\n",
    "# )\n",
    "\n",
    "# human_msg = HumanMessage(\n",
    "#     content=\"Please generate the python code for the report.\"\n",
    "# )\n",
    "\n",
    "# response = llm_with_tools.invoke([sys_msg, human_msg])\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e2534-96c8-4edf-b214-c8d526b6c48a",
   "metadata": {},
   "source": [
    "### TODO List\n",
    "- Make sure JS server is working as intended.\n",
    "- Convert ipynb to py .\n",
    "- Give the llm the tool.\n",
    "- Test the llm with tool.\n",
    "- Test the agent.\n",
    "- Wrap everything in a Start,End and toolNode.\n",
    "\n",
    "I should start taking caffeine seriously! 23:30 is too early to sleep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
